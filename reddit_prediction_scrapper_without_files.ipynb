{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reddit_prediction_scrapper_without_files.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfVzYIZbgNdaNd+blFHvdA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jlieow/tools/blob/master/reddit_prediction_scrapper_without_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V7FqZjJKcyz"
      },
      "source": [
        "#!!!THIS IS A PUBLIC COPY!!!\n",
        "#!!!PLEASE SAVE A COPY TO YOUR OWN DRIVE!!! GO to File >  Save a copy in drive\n",
        "#DO NOT SAVE ANYTHING TO THIS COPY!!!\n",
        "#!!!ANYTHING SAVED HERE IS VISIBLE TO EVERYONE!!!\n",
        "\n",
        "#Prior to running this in Colab, you need to add 4 files into root/content.\n",
        "#In the sidebar, there should be a folder icon. Click it to navigate to the directory.\n",
        "#You should be inside root/content and see 2 folders, 'Up one level' and sample_data.\n",
        "#In order to add files, click on 'Up one level to navigate into /root. \n",
        "#There are 3 dots on the right side of the folder 'content'. Go to 3 dots > New file and add the following files: \n",
        "##CLIENT_ID.txt\n",
        "##SECRET_KEY.txt\n",
        "##PW.txt\n",
        "##ARTICLE_ID.txt\n",
        "\n",
        "#CLIENT_ID.txt and SECRET_KEY.txt values are taken from reddit page https://www.reddit.com/prefs/apps.\n",
        "#In the page, click on the 'create another app...' button at the bottom of the page. \n",
        "#Input the name of your app, select script and include a redirect URI.\n",
        "#The values value under 'personal use script' and 'secret' should be generated for you.\n",
        "##Insert the value under 'personal use script' into CLIENT_ID.txt\n",
        "##Insert the value under 'secret' into SECRET_KEY.txt\n",
        "\n",
        "#PW.txt is your reddit password\n",
        "#If you sign in using a third party authenticator like gmail, you would not have registered a password and would need to reset it. \n",
        "#You can reset your password either via the login page, or by enabling 'two factor authentication' under the reddit page https://www.reddit.com/settings/privacy.\n",
        "##Insert the value into PW.txt\n",
        "\n",
        "#ARTICLE_ID.txt is your article that you are targetting to scrape\n",
        "##Example from actual URL see ARTICLE_ID after '/comments/':\n",
        "##https://www.reddit.com/r/TSLALounge/comments/npuzji/friday_predictions_june_4/\n",
        "##ARTICLE_ID = npuzji\n",
        "##Insert the value into ARTICLE_ID.txt\n",
        "\n",
        "###Each file should only contain the value and nothing else\n",
        "###If done correctly, code should execute without flaw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_S8hb_INowt"
      },
      "source": [
        "#Reading CLIENT_ID, SECRET_KEY, PW and ARTICLE_ID from file in /content\n",
        "#Preparing CLIENT_ID and SECRET_KEY from reddit page https://www.reddit.com/prefs/apps\n",
        "with open('CLIENT_ID.txt', 'r') as f:\n",
        "  CLIENT_ID = f.read()\n",
        "\n",
        "with open('SECRET_KEY.txt', 'r') as f:\n",
        "  SECRET_KEY = f.read()\n",
        "\n",
        "#Preparing PW \n",
        "with open('PW.txt', 'r') as f:\n",
        "  PW = f.read()\n",
        "\n",
        "#Preparing ARTICLE \n",
        "with open('ARTICLE_ID.txt', 'r') as f:\n",
        "  ARTICLE_ID = f.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-JcH7fSK_9b"
      },
      "source": [
        "#Use CLIENT_ID, SECRET_KEY and PW to get TOKEN\n",
        "import requests\n",
        "\n",
        "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
        "\n",
        "data = {\n",
        "    'grant_type': 'password',\n",
        "    'username': 'bullheadedbear',\n",
        "    'password': PW\n",
        "}\n",
        "\n",
        "headers = {'User-Agent': 'MyAPI/0.0.1'}\n",
        "\n",
        "res = requests.post('https://www.reddit.com/api/v1/access_token', auth=auth, data=data, headers=headers)\n",
        "\n",
        "TOKEN = res.json()['access_token']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kb64_AsLfrm"
      },
      "source": [
        "#Insert TOKEN into HTTP header\n",
        "headers = {**headers, **{'Authorization': f'bearer {TOKEN}'}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuJoRnt3LoBd",
        "outputId": "b90e28a8-818a-4761-9046-48134cc62e5d"
      },
      "source": [
        "#Test Response\n",
        "#200 = Successful/Authorized\n",
        "#Response 403 = Forbidden/Unauthorized (Likely due to incorrect TOKEN in HTTP header)\n",
        "requests.get('https://oauth.reddit.com/api/v1/me', headers=headers)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Response [200]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJp8dHvzL7MA"
      },
      "source": [
        "#Import pandas lib\n",
        "import pandas as pd\n",
        "\n",
        "#Get the comment tree for a given Article \n",
        "prediction_res = requests.get('https://oauth.reddit.com/r/TSLALounge/comments/' + ARTICLE_ID, headers=headers).json()\n",
        "\n",
        "prediction_df = pd.DataFrame()\n",
        "\n",
        "for post in prediction_res[1]['data']['children']:\n",
        "  prediction_df = prediction_df.append({\n",
        "      'author': post['data']['author'],\n",
        "      'body': post['data']['body'],\n",
        "  }, ignore_index=True)\n",
        "\n",
        "prediction_df"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}